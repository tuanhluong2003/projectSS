{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b969b25-5faa-46a3-bd4d-3b7ca4c955ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e022cf4a-ce2f-479b-9ca2-830abfa6e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 1: Tải mô hình VGG16 đã được huấn luyện trước\n",
    "base_model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "910d1101-0cec-4546-a11a-50da1538d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 2: Xóa lớp phân loại phía trên cùng để chỉ lấy phần trích xuất đặc trưng\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92932a7-8691-42a3-9822-b95615ee2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm phát hiện và cắt khuôn mặt từ ảnh\n",
    "def detect_faces(image):\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5825001-6425-4add-ba13-9c7794266adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chuẩn bị ảnh để đưa vào VGG16\n",
    "def preprocess_face(face_img):\n",
    "    face_img_resized = cv2.resize(face_img, (224, 224))  # VGG16 yêu cầu ảnh 224x224\n",
    "    face_img_resized = np.expand_dims(face_img_resized, axis=0)  # Thêm batch dimension\n",
    "    face_img_resized = preprocess_input(face_img_resized)  # Chuẩn hóa cho VGG16\n",
    "    return face_img_resized\n",
    "\n",
    "# Hàm trích xuất đặc trưng từ khuôn mặt bằng VGG16\n",
    "def extract_face_embedding(face_img):\n",
    "    preprocessed_face = preprocess_face(face_img)\n",
    "    embedding_vector = model.predict(preprocessed_face)\n",
    "    return embedding_vector\n",
    "\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2.T)  # Tính tích vô hướng\n",
    "    norm_vector1 = norm(vector1)  # Độ dài vector 1\n",
    "    norm_vector2 = norm(vector2)  # Độ dài vector 2\n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)  # Cosine similarity\n",
    "    return similarity[0][0]  # Lấy giá trị trong mảng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e3a1f4-8c92-4317-8038-a52656562d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step\n",
      "Embedding vector: [[ 0.         4.2806897  3.959217  ...  0.         4.5188637 10.678509 ]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step\n",
      "Embedding vector: [[ 0.         0.         3.8587227 ...  0.         6.1929526 12.269652 ]]\n",
      "Độ tương tự giữa 2 ảnh: 0.70428466796875\n",
      "The two faces are likely the same person.\n"
     ]
    }
   ],
   "source": [
    "# Main pipeline\n",
    "image_path1 = r'C:\\Users\\ATUS\\Desktop\\Pycharm\\faceRC\\km.jpg'\n",
    "image1 = cv2.imread(image_path1)\n",
    "\n",
    "\n",
    "image_path2 = r'C:\\Users\\ATUS\\Desktop\\Pycharm\\faceRC\\km1.jpg'\n",
    "image2 = cv2.imread(image_path2)\n",
    "\n",
    "# Bước 1: Phát hiện khuôn mặt trong ảnh\n",
    "faces1 = detect_faces(image1)\n",
    "faces2 = detect_faces(image2)\n",
    "\n",
    "\n",
    "# Bước 2: Trích xuất đặc trưng cho mỗi khuôn mặt\n",
    "# ảnh 1\n",
    "x1, y1, w1, h1 = faces1[0]\n",
    "face_img1 = image1[y1:y1+h1, x1:x1+w1]  # Cắt khuôn mặt từ ảnh gốc\n",
    "cv2.imshow('Detected Face1', face_img1)\n",
    "vector1 = extract_face_embedding(face_img1)  # Trích xuất vector đặc trưng bằng VGG16\n",
    "print(\"Embedding vector:\", vector1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ảnh 2\n",
    "x2, y2, w2, h2 = faces2[0]\n",
    "face_img2 = image2[y2:y2+h2, x2:x2+w2]  # Cắt khuôn mặt từ ảnh gốc\n",
    "cv2.imshow('Detected Face2', face_img2)\n",
    "vector2 = extract_face_embedding(face_img2)  # Trích xuất vector đặc trưng bằng VGG16\n",
    "print(\"Embedding vector:\", vector2)\n",
    "\n",
    "\n",
    "similarity = cosine_similarity(vector1, vector2)\n",
    "print(f\"Độ tương tự giữa 2 ảnh: {similarity}\") \n",
    "\n",
    "threshold = 0.6\n",
    "if similarity > threshold:\n",
    "    print(\"The two faces are likely the same person.\")\n",
    "else:\n",
    "    print(\"The two faces are likely different people.\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
